{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "from keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Dense,Dropout,Activation,Conv2D,MaxPooling2D,BatchNormalization,Flatten\nfrom keras.models import Sequential\nfrom keras.optimizers import rmsprop_v2\nfrom keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint\nfrom keras.models import load_model\n\n\nimport cv2\nfrom PIL import Image\nimport numpy as np\nimport pandas as pd\nimport os\nfrom keras.utils.np_utils import to_categorical\nimport seaborn as sns\n\n",
      "metadata": {},
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "int2emotions = {0:'Angry',1:'Fear',2:'Happy',3:'Neutral',4:'Sad',5:'Surprise'}\nemotions2int = {'Angry':0,'Fear':1,'Happy':2,'Neutral':3,'Sad':4,'Surprise':5}\n\n\ndic = {'images':[], 'labels':[], 'purpose':[]}\n    \n    \n    \nfor d in os.listdir('fer2013/'):\n    print(d)\n    for emotion in os.listdir(f'fer2013/{d}'):\n        print(emotion)\n        for i in os.listdir(f'fer2013/{d}/{emotion}'):\n            img = cv2.imread(f'fer2013/{d}/{emotion}/{i}',0)\n            img = img.reshape(48,48,1)\n            \n            dic['images'].append(img)\n            dic['labels'].append(emotion)\n            \n            if d=='train':\n                dic['purpose'].append('T')\n            else:\n                dic['purpose'].append('V')",
      "metadata": {},
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "train\n\nAngry\n\nFear\n\nHappy\n\nNeutral\n\nSad\n\nSurprise\n\nvalidation\n\nAngry\n\nFear\n\nHappy\n\nNeutral\n\nSad\n\nSurprise\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "df = pd.DataFrame(dic)\ndf.head()",
      "metadata": {},
      "execution_count": 3,
      "outputs": [
        {
          "execution_count": 3,
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>images</th>\n",
              "      <th>labels</th>\n",
              "      <th>purpose</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[[72], [78], [81], [75], [59], [54], [63], [6...</td>\n",
              "      <td>Angry</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[[152], [149], [147], [157], [146], [133], [1...</td>\n",
              "      <td>Angry</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[[117], [116], [114], [99], [77], [54], [36],...</td>\n",
              "      <td>Angry</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[[159], [159], [145], [159], [165], [162], [1...</td>\n",
              "      <td>Angry</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[[254], [253], [255], [251], [235], [186], [1...</td>\n",
              "      <td>Angry</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              images labels purpose\n",
              "0  [[[72], [78], [81], [75], [59], [54], [63], [6...  Angry       T\n",
              "1  [[[152], [149], [147], [157], [146], [133], [1...  Angry       T\n",
              "2  [[[117], [116], [114], [99], [77], [54], [36],...  Angry       T\n",
              "3  [[[159], [159], [145], [159], [165], [162], [1...  Angry       T\n",
              "4  [[[254], [253], [255], [251], [235], [186], [1...  Angry       T"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "train_data = df[df['purpose']=='T']\nval_data = df[df['purpose']=='V']",
      "metadata": {
        "scrolled": true
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "train_data.head()",
      "metadata": {},
      "execution_count": 5,
      "outputs": [
        {
          "execution_count": 5,
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>images</th>\n",
              "      <th>labels</th>\n",
              "      <th>purpose</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[[72], [78], [81], [75], [59], [54], [63], [6...</td>\n",
              "      <td>Angry</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[[152], [149], [147], [157], [146], [133], [1...</td>\n",
              "      <td>Angry</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[[117], [116], [114], [99], [77], [54], [36],...</td>\n",
              "      <td>Angry</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[[159], [159], [145], [159], [165], [162], [1...</td>\n",
              "      <td>Angry</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[[254], [253], [255], [251], [235], [186], [1...</td>\n",
              "      <td>Angry</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              images labels purpose\n",
              "0  [[[72], [78], [81], [75], [59], [54], [63], [6...  Angry       T\n",
              "1  [[[152], [149], [147], [157], [146], [133], [1...  Angry       T\n",
              "2  [[[117], [116], [114], [99], [77], [54], [36],...  Angry       T\n",
              "3  [[[159], [159], [145], [159], [165], [162], [1...  Angry       T\n",
              "4  [[[254], [253], [255], [251], [235], [186], [1...  Angry       T"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "val_data.head()",
      "metadata": {},
      "execution_count": 6,
      "outputs": [
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>images</th>\n",
              "      <th>labels</th>\n",
              "      <th>purpose</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>28273</th>\n",
              "      <td>[[[169], [117], [102], [89], [88], [74], [77],...</td>\n",
              "      <td>Angry</td>\n",
              "      <td>V</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28274</th>\n",
              "      <td>[[[137], [144], [65], [78], [91], [92], [96], ...</td>\n",
              "      <td>Angry</td>\n",
              "      <td>V</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28275</th>\n",
              "      <td>[[[8], [14], [8], [35], [148], [223], [241], [...</td>\n",
              "      <td>Angry</td>\n",
              "      <td>V</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28276</th>\n",
              "      <td>[[[83], [72], [63], [69], [79], [67], [87], [8...</td>\n",
              "      <td>Angry</td>\n",
              "      <td>V</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28277</th>\n",
              "      <td>[[[75], [80], [80], [80], [82], [92], [64], [2...</td>\n",
              "      <td>Angry</td>\n",
              "      <td>V</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  images labels purpose\n",
              "28273  [[[169], [117], [102], [89], [88], [74], [77],...  Angry       V\n",
              "28274  [[[137], [144], [65], [78], [91], [92], [96], ...  Angry       V\n",
              "28275  [[[8], [14], [8], [35], [148], [223], [241], [...  Angry       V\n",
              "28276  [[[83], [72], [63], [69], [79], [67], [87], [8...  Angry       V\n",
              "28277  [[[75], [80], [80], [80], [82], [92], [64], [2...  Angry       V"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "train_data['labels'].value_counts()",
      "metadata": {
        "scrolled": true
      },
      "execution_count": 7,
      "outputs": [
        {
          "execution_count": 7,
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Happy       7215\n",
              "Neutral     4965\n",
              "Sad         4830\n",
              "Fear        4097\n",
              "Angry       3995\n",
              "Surprise    3171\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "val_data['labels'].value_counts()",
      "metadata": {},
      "execution_count": 8,
      "outputs": [
        {
          "execution_count": 8,
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Happy       879\n",
              "Neutral     626\n",
              "Sad         594\n",
              "Fear        528\n",
              "Angry       491\n",
              "Surprise    416\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "happy_df = train_data[train_data['labels']=='Happy'].sample(n=3171)\nneutral_df = train_data[train_data['labels']=='Neutral'].sample(n=3171)\nsad_df = train_data[train_data['labels']=='Sad'].sample(n=3171)\nfear_df = train_data[train_data['labels']=='Fear'].sample(n=3171)\nangry_df = train_data[train_data['labels']=='Angry'].sample(n=3171)\nsurprise_df = train_data[train_data['labels']=='Surprise'].sample(n=3171)\n\ntrain_data = pd.concat([happy_df,neutral_df,sad_df,fear_df,angry_df,surprise_df])\n\n\n\ntrain_data = train_data.sample(frac=1)\ntrain_data.reset_index(inplace=True)\ntrain_data.drop('index',inplace=True,axis=1)\n\ntrain_data.head()",
      "metadata": {},
      "execution_count": 9,
      "outputs": [
        {
          "execution_count": 9,
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>images</th>\n",
              "      <th>labels</th>\n",
              "      <th>purpose</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[[148], [163], [173], [175], [138], [122], [1...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[[58], [43], [50], [62], [57], [49], [43], [3...</td>\n",
              "      <td>Angry</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[[22], [0], [5], [17], [0], [16], [119], [229...</td>\n",
              "      <td>Angry</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[[191], [176], [128], [137], [134], [145], [1...</td>\n",
              "      <td>Surprise</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[[193], [192], [194], [194], [205], [212], [2...</td>\n",
              "      <td>Sad</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              images    labels purpose\n",
              "0  [[[148], [163], [173], [175], [138], [122], [1...   Neutral       T\n",
              "1  [[[58], [43], [50], [62], [57], [49], [43], [3...     Angry       T\n",
              "2  [[[22], [0], [5], [17], [0], [16], [119], [229...     Angry       T\n",
              "3  [[[191], [176], [128], [137], [134], [145], [1...  Surprise       T\n",
              "4  [[[193], [192], [194], [194], [205], [212], [2...       Sad       T"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "train_data['labels'].value_counts()",
      "metadata": {},
      "execution_count": 10,
      "outputs": [
        {
          "execution_count": 10,
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sad         3171\n",
              "Angry       3171\n",
              "Happy       3171\n",
              "Surprise    3171\n",
              "Fear        3171\n",
              "Neutral     3171\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "batch_size= 32\nclasses = 6\nrows,columns=48,48",
      "metadata": {},
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "train_labels = list(train_data['labels'].replace(emotions2int))\ntrain_labels = to_categorical(train_labels)\n\nval_labels = list(val_data['labels'].replace(emotions2int))\nval_labels = to_categorical(val_labels)",
      "metadata": {},
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "train_data = list(train_data['images'])\ntrain_data = np.array(train_data)\n\nval_data = list(val_data['images'])\nval_data = np.array(val_data)",
      "metadata": {},
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "train_data.shape",
      "metadata": {},
      "execution_count": 15,
      "outputs": [
        {
          "execution_count": 15,
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19026, 48, 48, 1)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "val_data.shape",
      "metadata": {},
      "execution_count": 16,
      "outputs": [
        {
          "execution_count": 16,
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3534, 48, 48, 1)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "model = Sequential()\n\n# First Block\nmodel.add(Conv2D(64,(3,3),activation='elu',input_shape=(rows,columns,1),kernel_initializer='he_normal',padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64,(3,3),activation='elu',input_shape=(rows,columns,1),kernel_initializer='he_normal',padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.2))\n\n# Second Block\nmodel.add(Conv2D(128,(3,3),activation='elu',kernel_initializer='he_normal',padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(128,(3,3),activation='elu',kernel_initializer='he_normal',padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.2))\n\n# Third Block\nmodel.add(Conv2D(256,(3,3),activation='elu',kernel_initializer='he_normal',padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(256,(3,3),activation='elu',kernel_initializer='he_normal',padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.2))\n\n# Fourth Block\nmodel.add(Conv2D(512,(3,3),activation='elu',kernel_initializer='he_normal',padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(512,(3,3),activation='elu',kernel_initializer='he_normal',padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.2))\n\n# Fifth Block\nmodel.add(Flatten())\nmodel.add(Dense(256,activation='elu',kernel_initializer='he_normal'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\n# Sixth Block\nmodel.add(Dense(128,activation='elu',kernel_initializer='he_normal'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\n# Seventh Block\nmodel.add(Dense(64,activation='elu',kernel_initializer='he_normal'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\n# Eighth Block\nmodel.add(Dense(classes,activation='softmax',kernel_initializer='he_normal'))\n\nprint(model.summary())",
      "metadata": {},
      "execution_count": 18,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Model: \"sequential\"\n\n_________________________________________________________________\n\nLayer (type)                 Output Shape              Param #   \n\n=================================================================\n\nconv2d (Conv2D)              (None, 48, 48, 64)        640       \n\n_________________________________________________________________\n\nbatch_normalization (BatchNo (None, 48, 48, 64)        256       \n\n_________________________________________________________________\n\nconv2d_1 (Conv2D)            (None, 48, 48, 64)        36928     \n\n_________________________________________________________________\n\nbatch_normalization_1 (Batch (None, 48, 48, 64)        256       \n\n_________________________________________________________________\n\nmax_pooling2d (MaxPooling2D) (None, 24, 24, 64)        0         \n\n_________________________________________________________________\n\ndropout (Dropout)            (None, 24, 24, 64)        0         \n\n_________________________________________________________________\n\nconv2d_2 (Conv2D)            (None, 24, 24, 128)       73856     \n\n_________________________________________________________________\n\nbatch_normalization_2 (Batch (None, 24, 24, 128)       512       \n\n_________________________________________________________________\n\nconv2d_3 (Conv2D)            (None, 24, 24, 128)       147584    \n\n_________________________________________________________________\n\nbatch_normalization_3 (Batch (None, 24, 24, 128)       512       \n\n_________________________________________________________________\n\nmax_pooling2d_1 (MaxPooling2 (None, 12, 12, 128)       0         \n\n_________________________________________________________________\n\ndropout_1 (Dropout)          (None, 12, 12, 128)       0         \n\n_________________________________________________________________\n\nconv2d_4 (Conv2D)            (None, 12, 12, 256)       295168    \n\n_________________________________________________________________\n\nbatch_normalization_4 (Batch (None, 12, 12, 256)       1024      \n\n_________________________________________________________________\n\nconv2d_5 (Conv2D)            (None, 12, 12, 256)       590080    \n\n_________________________________________________________________\n\nbatch_normalization_5 (Batch (None, 12, 12, 256)       1024      \n\n_________________________________________________________________\n\nmax_pooling2d_2 (MaxPooling2 (None, 6, 6, 256)         0         \n\n_________________________________________________________________\n\ndropout_2 (Dropout)          (None, 6, 6, 256)         0         \n\n_________________________________________________________________\n\nconv2d_6 (Conv2D)            (None, 6, 6, 512)         1180160   \n\n_________________________________________________________________\n\nbatch_normalization_6 (Batch (None, 6, 6, 512)         2048      \n\n_________________________________________________________________\n\nconv2d_7 (Conv2D)            (None, 6, 6, 512)         2359808   \n\n_________________________________________________________________\n\nbatch_normalization_7 (Batch (None, 6, 6, 512)         2048      \n\n_________________________________________________________________\n\nmax_pooling2d_3 (MaxPooling2 (None, 3, 3, 512)         0         \n\n_________________________________________________________________\n\ndropout_3 (Dropout)          (None, 3, 3, 512)         0         \n\n_________________________________________________________________\n\nflatten (Flatten)            (None, 4608)              0         \n\n_________________________________________________________________\n\ndense (Dense)                (None, 256)               1179904   \n\n_________________________________________________________________\n\nbatch_normalization_8 (Batch (None, 256)               1024      \n\n_________________________________________________________________\n\ndropout_4 (Dropout)          (None, 256)               0         \n\n_________________________________________________________________\n\ndense_1 (Dense)              (None, 128)               32896     \n\n_________________________________________________________________\n\nbatch_normalization_9 (Batch (None, 128)               512       \n\n_________________________________________________________________\n\ndropout_5 (Dropout)          (None, 128)               0         \n\n_________________________________________________________________\n\ndense_2 (Dense)              (None, 64)                8256      \n\n_________________________________________________________________\n\nbatch_normalization_10 (Batc (None, 64)                256       \n\n_________________________________________________________________\n\ndropout_6 (Dropout)          (None, 64)                0         \n\n_________________________________________________________________\n\ndense_3 (Dense)              (None, 6)                 390       \n\n=================================================================\n\nTotal params: 5,915,142\n\nTrainable params: 5,910,406\n\nNon-trainable params: 4,736\n\n_________________________________________________________________\n\nNone\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "checkpoint = ModelCheckpoint('model\\\\6_class_emotion_detector_V2.h5',\n                             save_best_only=True,\n                             mode='min',\n                             monitor='val_loss',\n                             verbose=1)\n\n\n\n\n\nearlystopping = EarlyStopping(patience=10,\n                             verbose=1,\n                             min_delta=0,\n                             monitor='val_loss',\n                             restore_best_weights=True)\n\n\n\n\n\ncallbacks = [checkpoint, earlystopping]\n\nmodel.compile(metrics=['accuracy'],\n             optimizer='rmsprop',\n             loss='categorical_crossentropy')\n\n\n\ntrain_samples = 28273\nvalidation_samples = 3534\nbatch_size = 64\nepochs=30",
      "metadata": {},
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "history = model.fit(train_data,\n                    train_labels,\n                    epochs=epochs,\n                    steps_per_epoch=train_samples//batch_size,\n                    validation_data=(val_data,val_labels),\n                    validation_steps=validation_samples//batch_size,\n                    callbacks=callbacks)",
      "metadata": {
        "scrolled": true
      },
      "execution_count": 21,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Epoch 1/30\n\n441/441 [==============================] - 67s 105ms/step - loss: 2.4345 - accuracy: 0.1823 - val_loss: 1.8593 - val_accuracy: 0.2281ss: 2.441\n\n\n\nEpoch 00001: val_loss improved from inf to 1.85933, saving model to model\\6_class_emotion_detector_V2.h5\n\nEpoch 2/30\n\n441/441 [==============================] - 44s 100ms/step - loss: 1.7370 - accuracy: 0.2698 - val_loss: 1.5590 - val_accuracy: 0.3831oss: 1\n\n\n\nEpoch 00002: val_loss improved from 1.85933 to 1.55897, saving model to model\\6_class_emotion_detector_V2.h5\n\nEpoch 3/30\n\n441/441 [==============================] - 44s 100ms/step - loss: 1.4838 - accuracy: 0.3964 - val_loss: 1.5069 - val_accuracy: 0.4270\n\n\n\nEpoch 00003: val_loss improved from 1.55897 to 1.50687, saving model to model\\6_class_emotion_detector_V2.h5\n\nEpoch 4/30\n\n441/441 [==============================] - 45s 102ms/step - loss: 1.3203 - accuracy: 0.4815 - val_loss: 1.4112 - val_accuracy: 0.4570\n\n\n\nEpoch 00004: val_loss improved from 1.50687 to 1.41115, saving model to model\\6_class_emotion_detector_V2.h5\n\nEpoch 5/30\n\n441/441 [==============================] - 45s 102ms/step - loss: 1.2400 - accuracy: 0.5207 - val_loss: 1.3587 - val_accuracy: 0.4994\n\n\n\nEpoch 00005: val_loss improved from 1.41115 to 1.35871, saving model to model\\6_class_emotion_detector_V2.h5\n\nEpoch 6/30\n\n441/441 [==============================] - 44s 100ms/step - loss: 1.1692 - accuracy: 0.5500 - val_loss: 1.3683 - val_accuracy: 0.5207\n\n\n\nEpoch 00006: val_loss did not improve from 1.35871\n\nEpoch 7/30\n\n441/441 [==============================] - 44s 100ms/step - loss: 1.1047 - accuracy: 0.5777 - val_loss: 1.4137 - val_accuracy: 0.5144\n\n\n\nEpoch 00007: val_loss did not improve from 1.35871\n\nEpoch 8/30\n\n441/441 [==============================] - 47s 106ms/step - loss: 1.0264 - accuracy: 0.6175 - val_loss: 1.4424 - val_accuracy: 0.5198\n\n\n\nEpoch 00008: val_loss did not improve from 1.35871\n\nEpoch 9/30\n\n441/441 [==============================] - 45s 103ms/step - loss: 0.9633 - accuracy: 0.6439 - val_loss: 1.4911 - val_accuracy: 0.5354\n\n\n\nEpoch 00009: val_loss did not improve from 1.35871\n\nEpoch 10/30\n\n441/441 [==============================] - 45s 102ms/step - loss: 0.8602 - accuracy: 0.6902 - val_loss: 1.5004 - val_accuracy: 0.5306\n\n\n\nEpoch 00010: val_loss did not improve from 1.35871\n\nEpoch 11/30\n\n441/441 [==============================] - 45s 103ms/step - loss: 0.7719 - accuracy: 0.7283 - val_loss: 1.5959 - val_accuracy: 0.5323\n\n\n\nEpoch 00011: val_loss did not improve from 1.35871\n\nEpoch 12/30\n\n441/441 [==============================] - 46s 104ms/step - loss: 0.7067 - accuracy: 0.7582 - val_loss: 1.7697 - val_accuracy: 0.5405\n\n\n\nEpoch 00012: val_loss did not improve from 1.35871\n\nEpoch 13/30\n\n441/441 [==============================] - 45s 102ms/step - loss: 0.6299 - accuracy: 0.7863 - val_loss: 1.8730 - val_accuracy: 0.5396\n\n\n\nEpoch 00013: val_loss did not improve from 1.35871\n\nEpoch 14/30\n\n441/441 [==============================] - 45s 102ms/step - loss: 0.5385 - accuracy: 0.8201 - val_loss: 2.0165 - val_accuracy: 0.5311\n\n\n\nEpoch 00014: val_loss did not improve from 1.35871\n\nEpoch 15/30\n\n441/441 [==============================] - 44s 100ms/step - loss: 0.4990 - accuracy: 0.8362 - val_loss: 2.1729 - val_accuracy: 0.5351\n\n\n\nEpoch 00015: val_loss did not improve from 1.35871\n\nEpoch 16/30\n\n441/441 [==============================] - 44s 100ms/step - loss: 0.4147 - accuracy: 0.8622 - val_loss: 2.2819 - val_accuracy: 0.5306\n\n\n\nEpoch 00016: val_loss did not improve from 1.35871\n\nEpoch 17/30\n\n441/441 [==============================] - 45s 102ms/step - loss: 0.3770 - accuracy: 0.8758 - val_loss: 2.2751 - val_accuracy: 0.5232\n\n\n\nEpoch 00017: val_loss did not improve from 1.35871\n\nEpoch 18/30\n\n441/441 [==============================] - 46s 104ms/step - loss: 0.3327 - accuracy: 0.8927 - val_loss: 2.3443 - val_accuracy: 0.5368\n\n\n\nEpoch 00018: val_loss did not improve from 1.35871\n\nEpoch 19/30\n\n441/441 [==============================] - 44s 100ms/step - loss: 0.2970 - accuracy: 0.9046 - val_loss: 2.4195 - val_accuracy: 0.5308\n\n\n\nEpoch 00019: val_loss did not improve from 1.35871\n\nEpoch 20/30\n\n441/441 [==============================] - 45s 102ms/step - loss: 0.2959 - accuracy: 0.9085 - val_loss: 2.5389 - val_accuracy: 0.5175\n\n\n\nEpoch 00020: val_loss did not improve from 1.35871\n\nEpoch 21/30\n\n441/441 [==============================] - 45s 103ms/step - loss: 0.2503 - accuracy: 0.9216 - val_loss: 2.4581 - val_accuracy: 0.5328\n\n\n\nEpoch 00021: val_loss did not improve from 1.35871\n\nEpoch 22/30\n\n441/441 [==============================] - 44s 100ms/step - loss: 0.2248 - accuracy: 0.9312 - val_loss: 2.7538 - val_accuracy: 0.5467\n\n\n\nEpoch 00022: val_loss did not improve from 1.35871\n\nEpoch 23/30\n\n441/441 [==============================] - 45s 102ms/step - loss: 0.2407 - accuracy: 0.9282 - val_loss: 2.7193 - val_accuracy: 0.5246\n\n\n\nEpoch 00023: val_loss did not improve from 1.35871\n\nEpoch 24/30\n\n441/441 [==============================] - 44s 100ms/step - loss: 0.2242 - accuracy: 0.9328 - val_loss: 2.6998 - val_accuracy: 0.5399\n\n\n\nEpoch 00024: val_loss did not improve from 1.35871\n\nEpoch 25/30\n\n441/441 [==============================] - 45s 102ms/step - loss: 0.1839 - accuracy: 0.9452 - val_loss: 2.7879 - val_accuracy: 0.5348\n\n\n\nEpoch 00025: val_loss did not improve from 1.35871\n\nEpoch 26/30\n\n441/441 [==============================] - 45s 102ms/step - loss: 0.1967 - accuracy: 0.9426 - val_loss: 2.7746 - val_accuracy: 0.5351\n\n\n\nEpoch 00026: val_loss did not improve from 1.35871\n\nEpoch 27/30\n\n441/441 [==============================] - 45s 103ms/step - loss: 0.1774 - accuracy: 0.9462 - val_loss: 2.7664 - val_accuracy: 0.5402\n\n\n\nEpoch 00027: val_loss did not improve from 1.35871\n\nEpoch 28/30\n\n441/441 [==============================] - 45s 102ms/step - loss: 0.1648 - accuracy: 0.9511 - val_loss: 2.7768 - val_accuracy: 0.5306\n\n\n\nEpoch 00028: val_loss did not improve from 1.35871\n\nEpoch 29/30\n\n441/441 [==============================] - 44s 100ms/step - loss: 0.1644 - accuracy: 0.9489 - val_loss: 2.9112 - val_accuracy: 0.5345\n\n\n\nEpoch 00029: val_loss did not improve from 1.35871\n\nEpoch 30/30\n\n201/441 [============>.................] - ETA: 23s - loss: 0.1486 - accuracy: 0.9559- ETA: 25s - loss: 0WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 13230 batches). You may need to use the repeat() function when building your dataset.\n\n441/441 [==============================] - 22s 51ms/step - loss: 0.1564 - accuracy: 0.9548 - val_loss: 2.6819 - val_accuracy: 0.5359\n\n\n\nEpoch 00030: val_loss did not improve from 1.35871\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "model = load_model('model\\\\6_class_emotion_detector_V2.h5')\ncap = cv2.VideoCapture(0)\n\nclassifier = cv2.CascadeClassifier('Haarcascades\\\\haarcascade_frontalface_default.xml')\n\ndef detect_face(frame):\n    faces=classifier.detectMultiScale(frame,1.3,4)\n    if faces==():\n        return frame\n    \n    for x,y,w,h in faces:\n        cv2.rectangle(frame,(x,y),(x+w,y+h),(172,42,251),2)\n        face = frame[y:y+h,x:x+w]\n        face = cv2.cvtColor(face,cv2.COLOR_BGR2GRAY)\n        face = cv2.resize(face,(48,48))\n        face = face.reshape(1,48,48,1)\n        cv2.putText(frame,text=int2emotions[np.argmax(model.predict(face))],\n                    org=(x,y-15),fontFace=cv2.FONT_HERSHEY_SIMPLEX,fontScale=1,color=(106,40,243),thickness=2)\n    return frame\n\nwhile 1:\n    ret,frame= cap.read()\n    if ret==True:\n        cv2.imshow('emotion_detector',detect_face(frame))\n        if cv2.waitKey(1)==27:\n            break\n            \n            \ncap.release()\ncv2.destroyAllWindows()\n\n# karan jarawata\n",
      "metadata": {
        "scrolled": true
      },
      "execution_count": 23,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "<ipython-input-23-3171db864daa>:7: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n\n  if faces==():\n"
        }
      ]
    }
  ]
}